ClipFarmer is an end-to-end video processing system that converts long videos into short, vertical, attention-optimized clips by:-
->Detecting the loudest segment of the video (most engaging moment)
->Tracking faces frame-by-frame
->Cropping the video to a 9:16 vertical format, keeping the subject centered
->Preserving original audio
->Delivering a ready-to-post clip for platforms like Reels, Shorts, and TikTok
->The system is deployed on AWS EC2, powered by FastAPI, FFmpeg, MediaPipe, and a Next.js frontend.



How It Works (Pipeline)
User Upload
   ↓
Audio Analysis (FFmpeg)
   ↓
Extract Loudest 30s Segment
   ↓
Frame-by-frame Face Detection (MediaPipe)
   ↓
Smooth Center Tracking
   ↓
Vertical Crop (9:16)
   ↓
Audio Re-muxing
   ↓
Final Output Video



Architecture Overview

Frontend:-
Next.js (App Router)
Deployed on Vercel
Handles file selection, previews, and output playback

Backend:-
FastAPI (Python)
Hosted on AWS EC2
Handles video processing, ML inference, and FFmpeg orchestration

Processing Stack:-
FFmpeg → audio analysis & remuxing
MediaPipe (Face Detection) → subject tracking
OpenCV → frame manipulation




Running Locally

Backend (Python)::
Requirements:-
Python 3.10+ (recommended)
FFmpeg
Linux / WSL / macOS
pip install fastapi uvicorn mediapipe==0.10.14 opencv-python numpy
sudo apt install ffmpeg libgl1
Run:
uvicorn main:app --host 0.0.0.0 --port 8000
Access API docs:
http://localhost:8000/docs


Frontend (Next.js):-
cd frontend
npm install
npm run dev
Open:
http://localhost:3000




Deployment Notes:-

Backend (AWS EC2)
->Runs continuously using tmux or systemd
->Handles large video uploads and long-running processing jobs
->Designed to scale horizontally if needed

Frontend (Vercel)
->Static + client-side rendering
->Due to Vercel upload limits, large video uploads should be ->handled directly via the backend or object storage (S3/R2)



Known Limitations:-
-> Vercel API routes have upload size limits
-> MediaPipe on Python 3.12 can be unstable (Python 3.10 recommended)
-> Single-worker backend (by design) to avoid FFmpeg race conditions


Future Improvements:-
-> Progress tracking (WebSockets)
-> Multiple clip generation per video
-> S3 / Cloudflare R2 direct uploads
-> Multi-face prioritization
-> GPU acceleration
-> Batch processing & queues (Celery / Redis)


ClipFarmer isn’t a demo script — it’s a production-style system that combines:
-> Real ML inference
-> Real video pipelines
-> Real cloud deployment
-> Real frontend-backend integration
-> It reflects how modern AI-powered media products are actually built.


Author::
Basit Warsi
CSE @ IIT Jammu
Interests: Applied ML, Video Intelligence, Systems, Startups